
# AI HR Assistant - Flask POC with Custom Embeddings

This is a Proof-of-Concept (POC) for an AI-powered HR virtual assistant using:

- âœ… Flask (Web UI)
- âœ… LangChain (orchestration)
- âœ… Custom Embedding Model: `renshanhf/weighted-triplet-finetuned-model`
- âœ… FAISS (local vector search for POC)
- âœ… Azure OpenAI GPT-35 (LLM)
- âœ… Azure AI Content Safety (guardrails)

---

## ğŸ“¦ Features

- Fully containerized Flask web app
- Retrieval-Augmented Generation (RAG) pipeline
- Custom embeddings with your fine-tuned model
- Guardrails to ensure safe answers
- Runs locally or inside Docker
- Portable design for easy production upgrade

---

## ğŸ“‚ Project Structure

```bash
ai-hr-assistant-flask-poc/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Flask Web App
â”‚   â”œâ”€â”€ langchain_logic.py   # RAG Pipeline Orchestration
â”‚   â”œâ”€â”€ embeddings.py        # Embedding + Vector Search Logic
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html       # Simple Web UI
â”‚
â”œâ”€â”€ .env                     # Environment variables (secrets)
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ Dockerfile               # Docker build
â”œâ”€â”€ docker-compose.yml       # Local compose file
â””â”€â”€ README.md                # This file
```

âš™ï¸ Prerequisites
Python 3.10+ (for local dev)

Docker (for containerization)

Azure Account:

Azure OpenAI resource

Azure Content Safety resource

HuggingFace model access (for embedding model)

ğŸš€ Quickstart
1ï¸âƒ£ Clone Repository
```bash
git clone <your-repo-url>
cd ai-hr-assistant-flask-poc
```
2ï¸âƒ£ Setup Environment Variables
Create a .env file in the root directory:
```bash
AZURE_OPENAI_ENDPOINT=https://<your-openai-endpoint>.openai.azure.com/
AZURE_OPENAI_KEY=<your-openai-key>
AZURE_OPENAI_DEPLOYMENT=gpt-35-turbo

AZURE_CONTENT_SAFETY_ENDPOINT=https://<your-contentsafety-endpoint>.cognitiveservices.azure.com/
AZURE_CONTENT_SAFETY_KEY=<your-contentsafety-key>
â„¹ Note: We are using FAISS locally for vector search in this POC, so Azure Cognitive Search is not required for now.
```
3ï¸âƒ£ Build & Run Locally with Docker
Using plain Docker:
```bash
docker build -t hr-virtual-assistant .
docker run -p 5000:5000 --env-file .env hr-virtual-assistant
```
OR use docker-compose:
```bash
docker-compose up
```
4ï¸âƒ£ Open Web Interface
Open your browser and navigate to:
```bash
http://localhost:5000
```
âœ… Start asking HR questions!

ğŸ§  How It Works
1ï¸âƒ£ User enters HR question via web UI
2ï¸âƒ£ The question is embedded using your custom embedding model
3ï¸âƒ£ FAISS searches for top relevant documents locally
4ï¸âƒ£ LangChain injects context + question to Azure OpenAI LLM
5ï¸âƒ£ LLM generates response
6ï¸âƒ£ Azure Content Safety checks the response for unsafe content
7ï¸âƒ£ Answer displayed to user

ğŸš€ Next Steps
âœ… Add real HR documents into app/embeddings.py for better responses

âœ… Swap FAISS to Azure Cognitive Search for full enterprise deployment

âœ… Deploy Flask container to Azure Container Apps

âœ… Add CI/CD pipeline for automated deployment

ğŸ”’ Security Notes
Make sure secrets in .env are not committed into your version control

In production, move secrets to Azure Key Vault or container secrets

ğŸ“ Support
Contact AI Platform Engineering for support, architecture review, or production upgrade.

